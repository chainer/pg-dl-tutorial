# 2. 目的関数を定義する (4)

学習を行うために，入力と正解の出力のペアからなる $n$ 個の学習データ

$$D = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}$$

を用意します。

この学習データと，学習対象のモデルが一致するように，つまり学習データそれぞれ $(x_i, y_i)$ に対し， $p(y_i \mid x_i)$ が大きい時に，値が小さくなるような目的関数を用意します。

ここでは代表的な関数である`softmax_cross_entropy`とよばれる関数を使います。

```
# x は入力, tは正解の出力
h = MLP(x)
loss = F.softmax_cross_entropy(h, t)
```

ChainerではSoftmaxを適用した後に，クロスエントロピー損失関数を適用した目的関数が用意されています。
これは，二つまとめて処理をしないと，数値誤差の問題があるためです。


## クロスエントロピー損失関数 (*)

学習の目標は学習データ$D$の確率分布 $p(y|x)$ と，学習対象のモデルによる確率分布 $q(y \mid x; \theta)$ が一致するようにすることです。
確率分布間がどれだけ離れているかを表す指標としてKLダイバージェンスが知られています。
KLダイバージェンスは二つの確率分布 $P$ と $Q$ の遠さを次のように定義します。

```math
\begin{align}
KL(P \mid\mid Q) &= \sum_x P(x) \log \frac{P(x)}{Q(x)} \\
                 &= \sum_x P(x) \log P(x) - \sum_x P(x) \log Q(x)
\end{align}
```

もし， $P$ と $Q$ が同じならば，全ての $x$ について $\frac{P(x)}{Q(x)}=1$ となるので $KL(P \mid\mid Q)=0$ となります。
この二つの分布が違うと， $KL(P \mid\mid Q)>0$ となり，近ければ近いほど0に近づくような指標です。

学習データによって定義される確率分布は訓練分布と呼ばれ，それに基づく条件付き確率は

```math
\begin{align}
P(y \mid x) &= \frac{P(x, y)}{P(x)} \\
            &= \frac{\sum_{i}I(x=x_i, y=y_i)}{\sum_{i}I(x=x_i)}
\end{align}
```

と表されます。
但し， $I$ はデルタ関数とよばれ， $I(c)$ は $c$ が真である時は $1$，それ以外は $0$ であるような関数です。


訓練分布に基づく条件づき確率 $P(y \mid x)$ と，モデルによる条件づき確率 $Q(y \mid x)$ のKLダイバージェンスは

```math
\begin{align}
KL(P \mid\mid Q) &= \sum_{x} \sum_y P(y \mid x) \log \frac{P(y \mid x)}{Q(y \mid x)} \\
                 &= \sum_{x, y} P(y \mid x) \log P(y \mid x) - \sum_{x, y} P(y \mid x) \log Q(y \mid x)
\end{align}
```

となります。
この最適化において， $Q$ に依存する項は第二項のみであり， $(x, y) \in D$ の時 $P(y \mid x)=1$ ，それ以外 $0$ ですので

$L(\theta) = - \sum_{i=1}^n \log Q(y_i \mid x_i)$

となります。
これをクロスエントロピー損失関数，または負の対数尤度ともよばれます。

ここまで読んだ方で，なぜ学習データ $D$ から得られた確率分布 $P$ そのものを直接使わず，学習モデルによる確率 $Q$ を使うのかと思った方がいるかもしれません。
それは，学習の目標は学習データだけをうまく分類することではなく未知のデータをうまく分類することだからです。

$P$ は，入力が学習データと全く同じであればそれが正解となりますが，そうでない場合は確率分布が不定になりえます。
$Q$ はありえそうなモデルの中で一番 $P$ に近い分布を探しています。
$Q$ は $P$ とは違って全ての $x$ について確率分布を与えることができるため，学習データには含まれない未知のデータでもうまく分類できます。
別の言い方をすると$P$を平滑化した確率分布が$Q$となります。




