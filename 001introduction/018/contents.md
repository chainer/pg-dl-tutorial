# 機械学習のまとめ

これまで機械学習の手順についてみてきました。ここでおさらいしましょう。

1. 学習対象のモデルを定義する

    学習可能なパラメータを持つ関数をLinkとよび，関数をFunctionとよびます。
    学習対象のモデルはLinkとFunctionを組みわせて定義します。

2. 目的関数を定義する

    学習する目標を目的関数で表します。
    目的関数を最小化することで学習が実現されるように目的関数を定義します。
    目的関数は学習対象のモデルとそれを評価する関数によって定義できます。
    代表的な評価関数として，分類に対する `softmax_cross_entropy`，
    回帰に対する `mean_squared_error` があります。

3. 目的関数を最適化することで，モデルを学習する

    勾配降下法を利用し，目的関数を最小化するようなパラメータを求め，結果として学習を実現します。
    この勾配は誤差逆伝播法を利用し効率よく求められます。
    誤差逆伝播法は得られた損失の値に対し `backward()` を呼びだすことで求められます。
    求まった勾配を使って各パラメータを更新するためには，optimizersを使います。

次から具体的な学習問題を通じてもう一度詳しく見ていきますが，
その前にChainerで利用しているNumPyについて少し説明します。
