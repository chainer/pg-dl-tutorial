# Chainerの基本：backward 後ろ向き計算

Variableオブジェクトは値だけではなく，それまでの計算履歴を全て持っています。
この計算履歴にはどの変数と変数をどのような演算で組み合わせたかという情報を全て持っています。
このような計算履歴は計算グラフとも呼ばれます。

## メモ

この計算履歴はdump_graphを使って図示化することができます。使い方は[mnist example](https://github.com/pfnet/chainer/blob/master/examples/mnist/train_mnist.py)を参照してください。

この計算履歴の情報を使って，最終的な値（スカラー値）に対する各変数についての勾配（gradient, grad）を計算することができます。
Chainerではこの勾配を後ろ向き計算（逆誤差伝播法）を使って効率的に求めることができます。

さきほどの演算結果であるVaribleオブジェクトyのbackward関数を呼び出すと勾配を計算し，yの計算結果に関連したVaribleのgrad属性に勾配をセットします。

```
y.backward()
print(x.grad)
```

値yの変数xについての勾配というのは，簡単に言えば$x$をほんの少しだけふやした時に，$y$がどの程度変わるのかという値です。

例えば，$y=2x$というのは，$x$をほんの少し$d$だけ増やした時，$y$は$2d$だけ増えます。
そのため$y=2x$という値の$x$についての勾配は（$x$によらず）2となります。

$x$がベクトルやテンソルの場合には，各要素について，他の要素を固定した上で，対象の要素だけを少しだけ動かした時にどの程度変わるのかという値になります。これは数学的には偏微分とよびます。

変数$x$がベクトルやテンソルの場合は勾配はその要素毎の偏微分を並べたベクトルやテンソルになります。
このため勾配ベクトルとよんだりもします。

また，勾配ベクトルは今の各変数をどの方向に動かしたら最も急激に関数が大きくなるのかという値を意味しています。
その逆に，勾配ベクトルの逆向きは最も急激に関数の値を小さくなる方向です。

backwardは基本的には損失関数の値などスカラー値に対して呼び出せます。
複数の値に対する偏微分を並べたものはヤコビアン行列とよびますがChainerではヤコビアン行列の計算はサポートしていません。
スカラー値でない場合，ユーザーが手動でgradを設定をすればbackwardを呼び出して計算することができます。

```
z = Variable(np.array([10, 20], dtype=np.float32))
zz = 2 * z

# これはエラー，backwardはスカラー値に対してしか基本的には呼び出せない
zz.backward()

# ユーザーがzzの勾配を設定すればbackwardを呼び出せる．これは何らかの値に対する勾配とみなせる
zz.grad = np.array([0.1, -0.1], dtype=np.float32)
zz.backward()
```

## 課題

右の例で，実際に求めた勾配を0.01倍したものを$x$に足した上で$y$の値が実際に大きくなっていることを確かめよ


